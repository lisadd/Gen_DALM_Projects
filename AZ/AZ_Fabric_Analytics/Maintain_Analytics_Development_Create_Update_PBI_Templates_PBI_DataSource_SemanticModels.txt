In Microsoft Fabric, creating and updating reusable Power BI assets is a key part of the analytics development lifecycle, enabling consistency and application lifecycle management (ALM). This process involves using different file types and platform features: 

Creating and Updating Reusable Assets 
	- Power BI template (.pbit) files: These files are used to create reusable report structures and layouts that can be shared across an organization. The template contains the report design, data source connections (without the data itself), and model structure, allowing others to connect their own data to the predefined format.
		- Create: In Power BI Desktop, after designing a report and model, you can select File > Export > Power BI template to save it as a .pbit file.
		- Update: You open the .pbit in Power BI Desktop, make changes to the layout or model structure, and then export it again as a template to overwrite the existing file or save a new version.


Power BI data source (.pbids) files: These files save specific data source connection details (server, database) so other users can easily connect to the correct source without manually entering the information.
	- Create: In Power BI Desktop, you can export these files from the Data source settings menu (File > Options and settings > Data source settings). You can also manually create or edit the file in a text editor.
	- Update: The .pbids file is a small text file. To update, you simply edit the connection information within the file using a text editor or re-export it from Power BI Desktop with the new settings.

- Shared semantic models: In Microsoft Fabric, semantic models (formerly datasets) can be centrally managed and shared, allowing multiple reports to be built from a single, consistent data model.
	- Create: You create a semantic model within a Fabric workspace, often based on data from a Lakehouse or Warehouse, and then publish it to the Power BI service.
	- Update: The semantic model can be updated in several ways:
	 - By modifying the model using the "Open data model" feature in the Fabric workspace.
         - By uploading an updated .pbix file from Power BI Desktop to the same workspace, overwriting the existing semantic model.
         - Using the XMLA endpoint for advanced ALM scenarios with external tools like Tabular Editor or Visual Studio.
         - Configuring data pipelines in Fabric to orchestrate data refresh processes, ensuring the underlying data stays current. 




///////////


Approach 1: Using Python to call Fabric REST APIs (for all requested assets) 
The standard approach for CI/CD and programmatic management of Power BI items is to save them as a Power BI project file (PBIP) in developer mode, which stores the report and semantic model definition in a folder structure. You then use the Fabric REST APIs (specifically Create Item and Update Item Definition) to deploy these definitions to a workspace. 

This method involves managing files locally (or in source control) and using Python to handle authentication and API calls. 

Prerequisites:

- An Azure AD (Microsoft Entra ID) access token for authentication.
- The PBIP file structure locally (a folder containing definition.pbir and definition.dataset).
- The Workspace ID and Item Name

# Code Example:

import requests
import json
import os

# Configuration
WORKSPACE_ID = "your_workspace_id"
ITEM_NAME = "your_item_name" # e.g., "SalesAnalysisReport"
PBI_PROJECT_PATH = "./SalesAnalysisReport.pbip" # Local path to your PBIP folder
ACCESS_TOKEN = "your_azure_ad_access_token"

HEADERS = {
    "Authorization": f"Bearer {ACCESS_TOKEN}",
    "Content-Type": "application/json"
}

FABRIC_API_BASE_URL = "api.fabric.microsoft.com"

def create_or_update_powerbi_item(workspace_id, item_name, project_path):
    """Creates or updates a Power BI item (report/semantic model) using the PBIP definition."""

    # In a real-world scenario, you would zip the contents of PBI_PROJECT_PATH 
    # and upload it as the definition. The FabricPS-PBIP PowerShell module 
    # handles this logic, but for Python, you need a custom implementation.

    # This example focuses on the API call structure. The actual payload 
    # would be the zipped data or a reference to it.
    
    # Check if item exists (List Items API not shown, assume we know if we need to create or update)
    
    # Placeholder for the definition payload (simplified)
    definition_payload = {
        "displayName": item_name,
        "description": "My reusable Power BI asset",
        # Real implementation needs to handle the file upload/definition properly
    }

    # Example: Create Item API call (use Update Item Definition if it exists)
    create_url = f"{FABRIC_API_BASE_URL}/{workspace_id}/items"
    
    print(f"Attempting to create/update item: {item_name}")

    # The actual implementation of the "Update Item Definition" API is likely what's needed
    # for existing items.
    update_url = f"{FABRIC_API_BASE_URL}/{workspace_id}/items/{item_name}/updateDefinition"

    # Note: This is complex and usually requires handling long-running operations (LRO)
    # Microsoft recommends using the provided PowerShell script wrapper for this.

    # Python approach might look more like this for general item creation:
    item_creation_url = f"api.fabric.microsoft.com/{workspace_id}/items"
    
    new_item_data = {
      "displayName": item_name,
      "type": "PowerBIReport", # or "PowerBI semantic model" (check exact type name)
      "description": "Programmatically created item"
    }

    response = requests.post(item_creation_url, headers=HEADERS, data=json.dumps(new_item_data))

    if response.status_code == 201:
        print(f"Item {item_name} created successfully.")
        return response.json().get("id")
    else:
        print(f"Failed to create item. Status code: {response.status_code}, Response: {response.text}")
        return None

# The precise mechanism for uploading .pbit or .pbids files via API 
# involves using the 'Update Item Definition' API with the specific file content.




/// Approach 2: Managing Shared Semantic Models with semantic-link: 


The semantic-link Python library is available within Fabric notebooks and provides an interface to interact with Power BI semantic models for data reading, metadata retrieval, and limited management tasks. It does not directly handle file uploads like .pbit but helps manage the semantic model once it's in the workspace. 


# This code runs inside a Microsoft Fabric Notebook environment
from sempy.fabric import list_semantic_models, list_tables, list_columns
from sempy import resolve_workspace_id

# Resolve the current workspace ID (optional if using default workspace)
workspace_name = "Your Fabric Workspace Name"
workspace_id = resolve_workspace_id(workspace_name)

print(f"Working in Workspace ID: {workspace_id}")

# List available semantic models
print("Available semantic models:")
display(list_semantic_models(workspace=workspace_id))

# Interact with a specific semantic model (read data/metadata)
# The library is more for data science interaction than asset *creation/update*
# of the underlying file structure.







///// NOTES: Summary of File/Asset Handling

.pbit files: These are primarily created from Power BI Desktop via File > Export > Power BI template. Programmatic use involves uploading this template via the Fabric REST APIs using the methodology described in Approach 1.

.pbids files: These are simple JSON files pointing to a data source. You can create/update these manually or generate the JSON structure using Python, then upload via the REST API for creating/updating a data source item.

Shared Semantic Models: These are the result of deploying a Power BI project (PBIP) or creating a model on a Lakehouse/Warehouse in Fabric. Management of the model structure is done via XMLA endpoints with compatible tools (like SSMS) or the Update Semantic Model Definition REST API. 

